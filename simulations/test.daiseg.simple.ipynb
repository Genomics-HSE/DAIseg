{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dbb2b4fc-03e2-4718-abcd-dec688ae9947",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "import os, shutil, subprocess, json, sys\n",
    "from importlib import reload\n",
    "from joblib import Parallel, delayed\n",
    "\n",
    "import msprime, tskit\n",
    "\n",
    "from pathlib import Path\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "import sims\n",
    "\n",
    "# Visualization defaults\n",
    "sns.set_theme(style=\"whitegrid\", palette=\"colorblind\")\n",
    "plt.rcParams['figure.figsize'] = (10, 6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dee8ea68-3a7e-44ab-978c-f824879704a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DIR 'sims' exists already. Clean up old files...\n"
     ]
    }
   ],
   "source": [
    "# parameters for simulation\n",
    "params = {\n",
    "    'chrom_length': 5e7,      # DNA sequence length in base pairs\n",
    "    'recomb_rate': 1e-8,      # Recombination rate (per bp per generation)\n",
    "    'mut_rate': 1.29e-8,      # Mutation rate (per bp per generation)\n",
    "    'gen_time': 29.0,         # Years per generation\n",
    "    'n_eu': 1,          # European samples\n",
    "    'n_af': 200,         # African samples\n",
    "    'n_nd': 10,      # Neanderthal sample number\n",
    "    'ploidy' : 2\n",
    "}\n",
    "\n",
    "# effective pop sizes in demography\n",
    "Ne = {\n",
    "    'anc': 18500,      # Common AMH-Neanderthal ancestor\n",
    "    'nd': 3400,     # Neanderthal population\n",
    "    'amh': 23000,           # Anatomically modern humans (pre-OoA)\n",
    "    'ooa': 1861,            # Out-of-Africa founders\n",
    "    'af': 27600,       # African population\n",
    "    'eu': 13377,      # European population\n",
    "    'eu_bottleneck': 1080,  # European bottleneck size\n",
    "    'eu_growth': 1450       # Post-bottleneck size\n",
    "}\n",
    "\n",
    "# split and migration times\n",
    "t = {\n",
    "    't_nd_migration': 55000 / params['gen_time'],    # Neanderthal migration into OOA\n",
    "    't_amh': 550000 / params['gen_time'],         # AMH-Neanderthal split  \n",
    "    't_ooa': 65700 / params['gen_time'],             # Out-of-Africa migration\n",
    "    't_nd_samples': 38000 / params['gen_time'],      # Neanderthal sampling time\n",
    "    't_eu_growth': 31900 / params['gen_time'],          # European growth start\n",
    "}\n",
    "\n",
    "OUTPUT_DIR = \"sims\"\n",
    "\n",
    "# Проверяем, существует ли папка\n",
    "if os.path.exists(OUTPUT_DIR):\n",
    "    print(f\"DIR '{OUTPUT_DIR}' exists already. Clean up old files...\")\n",
    "    shutil.rmtree(OUTPUT_DIR) # Удаляет папку рекурсивно вместе со всеми файлами\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "N_CHR, N_JOBS = 10, 4  # number of chr, -1 use all cores, N use N cores\n",
    "random_seeds = random.sample(range(1, 10**9), k=N_CHR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "867e979c-8881-40c0-84e9-9a0c8df02a7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All simulations are finished...All trees are in sims/\n",
      "Nd in EU tract table in sims/all.tracts.summary.csv\n"
     ]
    }
   ],
   "source": [
    "results = Parallel(n_jobs=N_JOBS)(\n",
    "    delayed(sims.process_one_chromosome)(seed, params, Ne, t, 0.03, OUTPUT_DIR) \n",
    "    for seed in random_seeds\n",
    ")\n",
    "print(f\"All simulations are finished...All trees are in {OUTPUT_DIR}/\")\n",
    "\n",
    "final_df = pd.concat(results, ignore_index=True)\n",
    "csv_path = os.path.join(OUTPUT_DIR, \"all.tracts.summary.csv\")\n",
    "final_df.to_csv(csv_path, index=False, sep='\\t')\n",
    "\n",
    "print(f\"Nd in EU tract table in {csv_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8fb20102-f45b-4819-8ccf-408b62110269",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running DAIseg in parallel for 10 chromosomes...\n",
      "Done! Saved to sims/all.inferred.tracts.tsv\n",
      "\n",
      "Performance per Class without usin EM...\n",
      "\n",
      "\n",
      "Total Analyzed Genome: 1,000,000,000.0 bp\n",
      "---------------------------------------------\n",
      "CLASS        | PRECISION  | RECALL     | F1-SCORE  \n",
      "---------------------------------------------\n",
      "Archaic      | 96.66%     | 85.18%     | 0.9056    \n",
      "Modern       | 99.48%     | 99.90%     | 0.9969    \n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "print(f\"Running DAIseg in parallel for {len(random_seeds)} chromosomes...\")\n",
    "# Run in parallel\n",
    "results = Parallel(n_jobs=N_JOBS)(\n",
    "    delayed(sims.run_daiseg_task)(seed, OUTPUT_DIR) \n",
    "    for seed in random_seeds\n",
    ")\n",
    "\n",
    "valid_dfs = [res for res in results if res is not None]\n",
    "if valid_dfs:\n",
    "    final_df = pd.concat(valid_dfs, ignore_index=True)    \n",
    "    final_output = os.path.join(OUTPUT_DIR, \"all.inferred.tracts.tsv\")\n",
    "    final_df.to_csv(final_output, sep='\\t', index=False)    \n",
    "    print(f\"Done! Saved to {final_output}\\n\")\n",
    "else:\n",
    "    print(\"No tracts found.\")\n",
    "\n",
    "print(\"Performance per Class without usin EM...\\n\\n\")\n",
    "res = sims.calculate_class_metrics(os.path.join(OUTPUT_DIR, \"all.tracts.summary.csv\"),\n",
    "                                   os.path.join(OUTPUT_DIR, \"all.inferred.tracts.tsv\"),\n",
    "                                   params['chrom_length'])\n",
    "\n",
    "print(f\"Total Analyzed Genome: {res['Total_BP']:,} bp\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'CLASS':<12} | {'PRECISION':<10} | {'RECALL':<10} | {'F1-SCORE':<10}\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'Archaic':<12} | {res['Archaic']['Precision']:<10.2%} | {res['Archaic']['Recall']:<10.2%} | {res['Archaic']['F1']:<10.4f}\")\n",
    "print(f\"{'Modern':<12} | {res['Modern']['Precision']:<10.2%} | {res['Modern']['Recall']:<10.2%} | {res['Modern']['F1']:<10.4f}\")\n",
    "print(\"-\" * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbf8f783-1827-449c-99ec-d1ebd697ebbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Batch EM pipeline on 10 files...\n",
      "Loading 10 files for Global EM & Inference...\n",
      " [obs.py] Loading BED windows...\n",
      "[obs.py] Loaded 50000 windows. Processing TSV...\n",
      "\n",
      " [obs.py] Processing done. Aggregating results...\n",
      " Observation sequences for HMM created successfully!\n",
      "Max differences in 1000bp window: 10\n",
      " [obs.py] Loading BED windows...\n",
      "[obs.py] Loaded 50000 windows. Processing TSV...\n",
      "\n",
      " [obs.py] Processing done. Aggregating results...\n",
      " Observation sequences for HMM created successfully!\n",
      "Max differences in 1000bp window: 10\n",
      " [obs.py] Loading BED windows...\n",
      "[obs.py] Loaded 50000 windows. Processing TSV...\n",
      "\n",
      " [obs.py] Processing done. Aggregating results...\n",
      " Observation sequences for HMM created successfully!\n",
      "Max differences in 1000bp window: 11\n",
      " [obs.py] Loading BED windows...\n",
      "[obs.py] Loaded 50000 windows. Processing TSV...\n",
      "\n",
      " [obs.py] Processing done. Aggregating results...\n",
      " Observation sequences for HMM created successfully!\n",
      "Max differences in 1000bp window: 10\n",
      " [obs.py] Loading BED windows...\n",
      "[obs.py] Loaded 50000 windows. Processing TSV...\n",
      "\n",
      " [obs.py] Processing done. Aggregating results...\n",
      " Observation sequences for HMM created successfully!\n",
      "Max differences in 1000bp window: 11\n",
      " [obs.py] Loading BED windows...\n",
      "[obs.py] Loaded 50000 windows. Processing TSV...\n",
      "\n",
      " [obs.py] Processing done. Aggregating results...\n",
      " Observation sequences for HMM created successfully!\n",
      "Max differences in 1000bp window: 12\n",
      " [obs.py] Loading BED windows...\n",
      "[obs.py] Loaded 50000 windows. Processing TSV...\n",
      "\n",
      " [obs.py] Processing done. Aggregating results...\n",
      " Observation sequences for HMM created successfully!\n",
      "Max differences in 1000bp window: 9\n",
      " [obs.py] Loading BED windows...\n",
      "[obs.py] Loaded 50000 windows. Processing TSV...\n",
      "\n",
      " [obs.py] Processing done. Aggregating results...\n",
      " Observation sequences for HMM created successfully!\n",
      "Max differences in 1000bp window: 9\n",
      " [obs.py] Loading BED windows...\n",
      "[obs.py] Loaded 50000 windows. Processing TSV...\n",
      "\n",
      " [obs.py] Processing done. Aggregating results...\n",
      " Observation sequences for HMM created successfully!\n",
      "Max differences in 1000bp window: 11\n",
      " [obs.py] Loading BED windows...\n",
      "[obs.py] Loaded 50000 windows. Processing TSV...\n",
      "\n",
      " [obs.py] Processing done. Aggregating results...\n",
      " Observation sequences for HMM created successfully!\n",
      "Max differences in 1000bp window: 9\n",
      "Data loaded. Starting Global EM optimization...\n",
      "Iter 1: LL=-1435762.27 | Rates: N=0.67914, AF=0.05636, I=0.04527\n",
      "Iter 2: LL=-1166998.82 | Rates: N=0.67946, AF=0.05607, I=0.04414\n",
      "Iter 3: LL=-1166997.56 | Rates: N=0.67947, AF=0.05607, I=0.04403\n",
      "Iter 4: LL=-1166997.56 | Rates: N=0.67947, AF=0.05607, I=0.04402\n",
      "Iter 5: LL=-1166997.56 | Rates: N=0.67947, AF=0.05607, I=0.04402\n",
      "Iter 6: LL=-1166997.56 | Rates: N=0.67947, AF=0.05607, I=0.04402\n",
      "Converged.\n",
      "Final Global Parameters: [0.67946903 0.0560729  0.04401728 0.02446552 0.03      ]\n",
      "Starting Inference on all files...\n",
      "Calculating emission scores...\n",
      "Running Viterbi...\n",
      "Processing gaps...\n",
      "Calculating emission scores...\n",
      "Running Viterbi...\n",
      "Processing gaps...\n",
      "Calculating emission scores...\n",
      "Running Viterbi...\n",
      "Processing gaps...\n",
      "Calculating emission scores...\n",
      "Running Viterbi...\n",
      "Processing gaps...\n",
      "Calculating emission scores...\n",
      "Running Viterbi...\n",
      "Processing gaps...\n",
      "Calculating emission scores...\n",
      "Running Viterbi...\n",
      "Processing gaps...\n",
      "Calculating emission scores...\n",
      "Running Viterbi...\n",
      "Processing gaps...\n",
      "Calculating emission scores...\n",
      "Running Viterbi...\n",
      "Processing gaps...\n",
      "Calculating emission scores...\n",
      "Running Viterbi...\n",
      "Processing gaps...\n",
      "Calculating emission scores...\n",
      "Running Viterbi...\n",
      "Processing gaps...\n",
      "Done! Processed 10 files.\n",
      "Saving merged results to ./sims/all.inferred.EM.tsv...\n"
     ]
    }
   ],
   "source": [
    "! python ../daiseg.py run.with.EM -jsons sims/config_seed_*.json -out ./sims/all.inferred.EM.tsv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "78c66148-3acc-4f30-982b-b9109556193f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Analyzed Genome: 1,000,000,000.0 bp\n",
      "---------------------------------------------\n",
      "CLASS        | PRECISION  | RECALL     | F1-SCORE  \n",
      "---------------------------------------------\n",
      "Archaic      | 97.02%     | 88.42%     | 0.9252    \n",
      "Modern       | 99.59%     | 99.90%     | 0.9975    \n",
      "---------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "gt_path = os.path.join(OUTPUT_DIR, \"all.tracts.summary.csv\")\n",
    "inf_path = os.path.join(OUTPUT_DIR, \"all.inferred.EM.tsv\")\n",
    "\n",
    "\n",
    "res = sims.calculate_class_metrics(gt_path, inf_path, params['chrom_length'])\n",
    "\n",
    "print(f\"Total Analyzed Genome: {res['Total_BP']:,} bp\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'CLASS':<12} | {'PRECISION':<10} | {'RECALL':<10} | {'F1-SCORE':<10}\")\n",
    "print(\"-\" * 45)\n",
    "print(f\"{'Archaic':<12} | {res['Archaic']['Precision']:<10.2%} | {res['Archaic']['Recall']:<10.2%} | {res['Archaic']['F1']:<10.4f}\")\n",
    "print(f\"{'Modern':<12} | {res['Modern']['Precision']:<10.2%} | {res['Modern']['Recall']:<10.2%} | {res['Modern']['F1']:<10.4f}\")\n",
    "print(\"-\" * 45)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5223002-00c2-4583-bf37-8249a367dc6e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
